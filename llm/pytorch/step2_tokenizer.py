import torch

print("\nğŸ”¹ Step 2: Tiny Dataset and Tokenizer ğŸ”¹\n")

# Tiny corpus
corpus = "I am Sree from Schogini.com"
print(f"ğŸ“š Tiny Corpus: {corpus}")

# Create vocabulary (set of unique characters)
vocab = sorted(set(corpus))
print(f"ğŸ”¤ Vocabulary: {vocab}")

# Mappings
char_to_idx = {ch: idx for idx, ch in enumerate(vocab)}
idx_to_char = {idx: ch for idx, ch in enumerate(vocab)}

print(f"ğŸ”¢ char_to_idx: {char_to_idx}")
print(f"ğŸ”¢ idx_to_char: {idx_to_char}")

# Encode corpus to integers
encoded = torch.tensor([char_to_idx[ch] for ch in corpus], dtype=torch.long)
print(f"ğŸ§© Encoded Corpus: {encoded}")

# Decode back
decoded = ''.join([idx_to_char[idx.item()] for idx in encoded])
print(f"ğŸ” Decoded Corpus: {decoded}")
