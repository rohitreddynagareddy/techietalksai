<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Learn-train-LLM-from basics</title>


<style type="text/css">
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}

kbd {
  display: inline-block;
  padding: 3px 5px;
  font-size: 11px;
  line-height: 10px;
  color: #555;
  vertical-align: middle;
  background-color: #fcfcfc;
  border: solid 1px #ccc;
  border-bottom-color: #bbb;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #bbb
}

* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>


</head>

<body>

<h1 id="toc_0">Learn LLM from Basics</h1>

<hr>

<h2 id="toc_1">1. Project Layout &amp; Getting Started</h2>

<hr>

<p>Folder contents:</p>

<div><pre><code class="language-none">• Dockerfile &amp; docker‑compose.yml  → isolate your environment
• run.sh                           → convenience wrapper (sh run.sh step2_tokenizer.py)
• step1_env_check.py … step12_mini‑decoder.py → twelve incremental Python scripts
• mini_gpt.pth                     → trained weights from step7
• notes.txt                        → your personal plan

Prerequisites:
• Git‑clone this folder
• Have Docker (optional) or a local PyTorch install
• (Optionally) run docker compose up step1 --build to verify PyTorch &amp; MPS/CPU</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 1: Environment Check (step1_env_check.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → make sure PyTorch is installed and pick the right device (CPU / GPU / Apple MPS)

Key concepts:
• torch.version
• torch.device(...)
• tensors live on “device” (CPU vs GPU vs MPS)

Running it prints your PyTorch version, host architecture, and creates a toy tensor to confirm everything works.</code></pre></div>

<hr>

<div><pre><code class="language-none">1. Step 2: Tiny Corpus &amp; Tokenizer (step2_tokenizer.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → turn text into numbers (“tokenization”)

Code highlights:
• corpus = “I am Sree from Schogini.com”
• vocab = sorted(set(corpus))  ➔ all unique characters
• char_to_idx, idx_to_char dicts
• encoded = torch.tensor([char_to_idx[ch] for ch in corpus])
• decoded back again with idx_to_char

Key concepts for beginners:
• Every NLP model works on numbers, not raw strings.
• Token = smallest unit (here, a character).
• Mapping str ↔ int lets us embed them in a neural net.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 3: Tiny Transformer (step3_tiny_transformer.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → define the simplest “transformer‐style” network: embed → linear → logits

Network:
• nn.Embedding(vocab_size, embedding_dim)
• nn.Linear(embedding_dim, vocab_size)

Forward pass:

    1. take a batch of token IDs
    2. embed into 16‑dim vectors
    3. project back to “vocab_size” scores (logits)

Logits are raw scores you’ll convert with softmax later.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 4: Forward Pass with Debugging (step4_forward_pass.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → walk through shapes &amp; values

Adds:
• builds tiny vocab from “hello world”
• prints out shapes at each stage, e.g.
   – Input IDs: [5]
   – After Embedding: [5×16]
   – After Linear: [5×vocab_size]

Why it matters:
• Verifying dimensions is the single most important debugging trick in deep learning.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 5: Tiny Training Loop (step5_train_simple.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → teach the model to predict next character in “hello”

Pipeline:

    1. encode “hello” → [h, e, l, l, o]
    2. x = first 4 tokens, y = last 4 tokens shifted by one
    3. forward(x) ➔ logits of shape [4×vocab_size]
    4. CrossEntropyLoss(logits, y)
    5. backprop + optimizer.step()
    6. print loss every 10 epochs

Key concepts:
• CrossEntropyLoss combines softmax + negative‑log‑likelihood
• optimizer.zero_grad(), loss.backward(), optimizer.step()
• predict next‑token is the core of autoregressive language models</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 6: Simple Inference &amp; Greedy Decoding (step6_simple_inference.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → after training, generate a sequence character‑by‑character

Greedy decoding:

    1. start with a single token (e.g. “h”)
    2. model(input_ids) ➔ logits
    3. softmax + argmax ➔ index of most probable next char
    4. append &amp; repeat

You’ll see the model output “hellllllllll…”, a sign it learned the pattern.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 7: Build a Mini‑GPT (step7_mini_gpt.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → a minimal GPT‑style block with:
• token + position embeddings
• causal self‑attention (nn.MultiheadAttention)
• feed‑forward (MLP)
• layer norms &amp; residual connections

Details:
• block_size = context window length
• position_embedding = nn.Embedding(2×block_size, dim)  (avoid overflow)
• attn_mask = upper‐triangular inf mask for causality
• train on random 8‑token chunks of “hello world” for 500 epochs
• save model.state_dict() → mini_gpt.pth

Key concepts:
• Positional encodings let the model know “where” tokens sit.
• Multi‑head self‑attention builds contextualized representations.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 8: Bonus—Inspecting One‑Head Attention (step8_bonus_multihead_mini_gpt.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → step through one‑head attention + residuals by printing intermediate shapes

Adds:
• print after embedding+positional, after attention, after feed‑forward
• single head (num_heads=1) for simplicity
• slide a 1‑batch training loop

This reinforces your mental model of the Transformer decoder block.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 9: Load &amp; Infer from Your Saved GPT (step9_load_and_infer.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → re‑instantiate the same MiniGPT class, load mini_gpt.pth, and sample

Key points:
• Your class definition must match exactly
• model.load_state_dict(torch.load(&quot;mini_gpt.pth&quot;))
• Use multinomial sampling for randomness
• Maintain a sliding context window to avoid infinite growth</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 10: Top‑k Sampling &amp; Long Context (step10_upgraded_top-k-sampling-long-context.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → replace greedy decoding with top‑k sampling and enforce a fixed context window

Top‑k sampling:

    1. take logits for last token
    2. pick the top k highest scores
    3. renormalize with softmax
    4. sample from that smaller distribution

Long context:
• always keep only the last block_size tokens as input

This mimics GPT‑style generation more closely.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 11: Temperature Control (step11_temperature.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → add temperature to control randomness

Temperature scaling:
• logits ← logits / T
   – T &gt; 1 → flattens (more random)
   – T &lt; 1 → sharpens (more deterministic)

Combined with top‑k, this gives you fine control over creativity vs coherence.</code></pre></div>

<hr>

<div><pre><code class="language-none">    1. Step 12: Building a Mini Decoder Block (step12_mini‑decoder.py)</code></pre></div>

<hr>

<div><pre><code class="language-none">Goal  → pull everything together into a reusable MiniDecoderBlock:

Layers:

    1. token + positional embeddings
    2. causal multi‑head attention (mask via a helper)
    3. add &amp; layer‑norm
    4. feed‑forward MLP
    5. add &amp; layer‑norm

You run it on dummy input (batch_size=2, seq_len=5) to confirm you get a (2×5×dim) output.</code></pre></div>

<hr>

<div><pre><code class="language-none">## Wrapping Up

• You now have a character‑level mini GPT from scratch.
• You’ve seen how tokenization, embeddings, attention, training loops, and sampling strategies all fit together.
• Try extending it: bigger vocab, different temperature schedules, beam search, or full word‑level tokenization.

Happy hacking! 🚀</code></pre></div>




</body>

</html>
